import requests
from bs4 import BeautifulSoup
import csv

def extract_products(url):
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, "html.parser")

    products = []

    # Example selectorsâ€”these need to be updated for the actual site structure
    for item in soup.select(".product"):  # Change selector as needed
        name = item.select_one(".product-title").get_text(strip=True) if item.select_one(".product-title") else "N/A"
        price = item.select_one(".product-price").get_text(strip=True) if item.select_one(".product-price") else "N/A"
        rating = item.select_one(".product-rating").get_text(strip=True) if item.select_one(".product-rating") else "N/A"
        products.append([name, price, rating])

    return products

def save_to_csv(products, filename):
    with open(filename, mode="w", newline='', encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Name", "Price", "Rating"])
        writer.writerows(products)

if __name__ == "__main__":
    url = "https://example-ecommerce-site.com/products"  # Replace with an actual page URL
    products = extract_products(url)
    save_to_csv(products, "products.csv")
    print("Scraping complete. Data saved to products.csv.")
